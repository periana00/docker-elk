input { 
    mongodb { 
        uri => 'mongodb://mongo:27017/news' 
        placeholder_db_dir => './' 
        placeholder_db_name => 'logstash_sqlite.db' 
        collection => 'sync'
        batch_size => 1000
        generateId => false 
        parse_method => "simple" 
    }
} 

filter {
    mutate {
        add_field => { "[@metadata][type]" => "article" }
        copy => { "_id" => "[@metadata][_id]" }
        remove_field => ["_id", "@timestamp", "@version", "host", "log_entry", "logdate", "test"]
    }
} 

output { 
    elasticsearch {
		hosts => ["elasticsearch:9200"]
		user => "logstash_internal"
		password => "${LOGSTASH_INTERNAL_PASSWORD}"
        index => "article-all" 
        document_id => "%{[@metadata][_id]}"
        action => "update"
        doc_as_upsert => true
        template => "/usr/share/logstash/config/es_index_config.json"
        template_name => "default"
        template_overwrite => true
    }
}